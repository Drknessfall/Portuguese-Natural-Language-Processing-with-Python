{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection\n",
    "\n",
    "Python provides some libraries for language detection:\n",
    "\n",
    "* [langdetect](https://pypi.python.org/pypi/langdetect/1.0.1) - LangDetect is language detection library ported from [Google's language-detection algorithm](https://github.com/shuyo/language-detection/blob/wiki/ProjectHome.md).\n",
    "* [langid](https://github.com/saffsd/langid.py) - LangId is a standalone Language Identification tool\n",
    "* [polyglot](https://pypi.python.org/pypi/polyglot) - Polyglot is a natural language pipeline that supports massive multilingual applications. Its language detection uses the Google Translate API\n",
    "\n",
    "The langdetect is the fastest and smaller, so the best library for the purpose. Althoug the libraries above are good estimators, they are not good enough to the language use we face in blogs and microblogs. The article [Language Detection for Twitter](https://shuyo.wordpress.com/2012/02/21/language-detection-for-twitter-with-99-1-accuracy/) presents an algorithm in python that helps the detection for that kind of text. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangDetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "# Simply detects the main languages\n",
    "detect(u'Eu falo Português')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[en:0.85714175108, pt:0.14285723368]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "# Or shows the probabilities for the detected languages\n",
    "detect_langs(u'Tudo bem brother?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hu:0.999996875725]\n"
     ]
    }
   ],
   "source": [
    "# Language Detection only performs reasonable with a text bigger than one word.\n",
    "detect_langs(u'Olá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[vi:0.571427435325, id:0.285714212192, en:0.142858299116]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and with formal language, not with slangs or internet language.\n",
    "detect_langs(u'Tah td bem c vc?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ku', 0.7003455583568504)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langid\n",
    "# Langid does have a good accuracy over short sentences\n",
    "langid.classify(u'Eu falo Português')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pt', 1.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langid.classify(u'Este texto é para demonstrar a assertividade do algoritmo de detecção de línguas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Portuguese'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polyglot.text import Text, Word\n",
    "text = Text(u'Eu falo Português')\n",
    "text.language.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method detect_language in module polyglot.text:\n",
      "\n",
      "detect_language(self) method of polyglot.text.Text instance\n",
      "    Detect the blob's language using the Google Translate API.\n",
      "    Requires an internet connection.\n",
      "    Usage:\n",
      "    ::\n",
      "        >>> b = Text(\"bonjour\")\n",
      "        >>> b.language\n",
      "        u'fr'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(text.detect_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
